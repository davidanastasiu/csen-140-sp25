{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02: Text Processing\n",
    "\n",
    "In this lab, you will pre-process the text data from your Program 1 assignment and practice computing at least two proximity measures using the sparse vectors you create from your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "\n",
    "Read in the data from train.dat and test.dat, split labels from text in the training data, and process the text in the training and test datasets into sparse matrices `train_data` and `test_data`. You may use and modify the code provided for you in the `Activity-data-3` example or use external libraries for this task. Note that both the training and test data must be in the same Euclidean space, i.e., each axis of the space should refer to the same token/word and there should be the same number of columns in the `train_data` and `test_data` matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from scipy.sparse import csr_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "def process_data(fpath, idx=None, is_training=True):\n",
    "    \"\"\"\n",
    "    This function processes the input data and returns the result.\n",
    "    \n",
    "    :param fpath: Input data to be processed\n",
    "    :param idx: Optional dictionary of tokens\n",
    "    :param is_training: Boolean flag indicating if the data is for training\n",
    "    :return: csr_matrix containing the term-frequency values for the input data after processing\n",
    "    \"\"\"\n",
    "    # Example processing: Read the data from fpath, split labels and features (if training data),\n",
    "    # tokenize it, optionally filter tokens, apply stemming or lematization (but not both), \n",
    "    # and finally convert the data to a csr_matrix format by counting token frequencies in each doc.\n",
    "\n",
    "    # For demonstration, we will return a dummy csr_matrix.\n",
    "    data = csr_matrix((3, 3), dtype=int)  # Dummy data for demonstration\n",
    "\n",
    "\n",
    "    return data\n",
    "    \n",
    "# Example usage\n",
    "idx = {}\n",
    "train_data = process_data('train.dat', idx=idx, is_training=True)\n",
    "test_data = process_data('test.dat', idx=idx, is_training=False)\n",
    "assert train_data.shape[1] == test_data.shape[1], \"Train and test data do not have the same number of features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "Now that you have the data, create efficient methods to compute at least one proximity function for samples in your data. In particular, to solve the k-NN problem you need to find the nearest neighbors within the training data (rows of `train_data`) for each of the test data points (rows of `test_data`). You may choose any proximity measures you would like. However, there are several requirements for this assignment:\n",
    "1. You may not use any external libraries other than functions inherent in the `csr_matrix` data structure.\n",
    "2. Your data matrix/vectors should not be changed from sparse to dense at any time during the computation.\n",
    "3. You should return a list of pairs containing the rows in `train_data` that have non-zero proximity to the sample and their associated proximity values.\n",
    "\n",
    "For best performance, computations should be vectorized whenever possible, i.e., you should compute vector-matrix or matrix-matrix operations rather than vector-vector operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proximities using proximity function: []\n"
     ]
    }
   ],
   "source": [
    "def proximity(train_data, x):\n",
    "    \"\"\"\n",
    "    This function computes the proximity of a given data point x to the training data.\n",
    "    \n",
    "    :param train_data: The training data in csr_matrix format\n",
    "    :param x: The data point for which proximity is to be computed\n",
    "    :return: list of pairs containing the rows in `train_data` that have non-zero proximity to the sample and their associated proximity values\n",
    "    \"\"\"\n",
    "    # Example proximity calculation (dummy implementation)\n",
    "    proximities = []\n",
    "    return proximities\n",
    "\n",
    "# Example usage \n",
    "x = test_data[0]\n",
    "proximities = proximity(train_data, x)\n",
    "print(f\"Top 3 proximities out of {len(proximities)} using proximity function:\", proximities[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "342wi25",
   "language": "python",
   "name": "342wi25"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
